[{"path":"https://stefanocoretta.github.io/lexa/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 Stefano Coretta Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://stefanocoretta.github.io/lexa/articles/database-schema.html","id":"general-structure","dir":"Articles","previous_headings":"","what":"General structure","title":"Lexa Database Schema","text":"Lexa database (lexadb) directory containing following files/dirs: config.yaml: database configuration file. grammar.yaml: grammar specification file. lexicon/: directory containing Lexa lexicon files. texts/: directory containing Lexa text collections (lexatxt). can find examples Lexa databases part lexa package (https://github.com/stefanocoretta/lexa/tree/main/inst/extdata). quickstart new database, just run: database called my_lexadb created working directory.","code":"library(lexa) create_lexadb(name = \"my_\")"},{"path":"https://stefanocoretta.github.io/lexa/articles/database-schema.html","id":"lexicon-file-schema","dir":"Articles","previous_headings":"","what":"Lexicon file schema","title":"Lexa Database Schema","text":"","code":"id: lx_00000n lexeme: <string> phon: <string> morph_category: <lexical, grammatical> morph_type: <root, stem, affix, clitic, particle, compound, phrase> part_of_speech: <string> inflectional_features:   <feature_n>: <string> etymology: <string> loan_word: <string> notes: [<string>] allomorphs:   al_0n:     id: al_0n     morph: <string>     phon: <string>     conditioning:       type: <phonological, morphosyntactic, free>       context: <string> senses:   se_0n:     id: se_0n     gloss: <string>     definition: <string>     literal: <string>     scientific: <string>     usage: <string>     inflectional_features:       <feature_n>: <string>     examples: [\"tx_00000n:st_00000n\"]     etymology: <string> crossref: [\"lx_00000n\"] variants: [<string>] semantics:   semantic_domain: [\"sd_00000n\"]   synonyms: [\"lx_00000n\"]   antonyms: [\"lx_00000n\"] date_created: <date> date_modified: <date>"},{"path":"https://stefanocoretta.github.io/lexa/articles/database-schema.html","id":"text-schema","dir":"Articles","previous_headings":"","what":"Text schema","title":"Lexa Database Schema","text":"Texts located texts/ folder. text saved separate .yaml file.","code":"id: tx_00000n title: <string> topic: <string> genre: <string> participants: [<string>] translators: [<string>] source: <string> sentences:   st_00000n:     sentence: <string>     transcription: <string>     transliteration: <string>     phon: <string>     morpho_phon: <string>     morpho: <string>     gloss: <string>     translation: <string>     literal: <string>     notes: [<string>] notes: [<string>]"},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Typesetting interlinear glosses","text":"Users can output interlinear glosses Rmarkdown files texts Lexa database. PDF HTML output formats supported. LaTeX package expex used PDF output, HTML glosses rendered Leipzig.js. time, functionalities implemented within lexa limited, provide sufficient coverage basic glossing.","code":""},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"load-a-lexa-database","dir":"Articles","previous_headings":"","what":"Load a Lexa database","title":"Typesetting interlinear glosses","text":"load Lexa database, first attach lexa package. load example database eleryon_lexadb. can now inspect content eleryon database.","code":"library(lexa) eleryon_path <- system.file(\"extdata/eleryon_lexadb\", package = \"lexa\")  eleryon <- load_lexadb(eleryon_path) #> ℹ Loading lexa database... eleryon #>  #> ── Database info ─────────────────────────────────────────────────────────────── #> ◉ Name: eleryon #> ℹ Entries: 6 | Texts: 1 #>  #> ── Lexicon breakdown ── #>  #> ◉ Categories → Lexical: 6 #> ◉ Morpheme types → Roots: 6 #> ◉ POS → Adverbs: 1 | Nouns: 1 | Verbs: 4"},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"include-interlinear-glosses","dir":"Articles","previous_headings":"","what":"Include interlinear glosses","title":"Typesetting interlinear glosses","text":"two ways including interlinear gloss Rmarkdown file.","code":""},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"inline-r-code","dir":"Articles","previous_headings":"Include interlinear glosses","what":"Inline R code","title":"Typesetting interlinear glosses","text":"One using inline R code (see source vignette code).  Ęs ętsu urųrtō enēim kę̄syoh bhųl enēim āireᵃph likhpyūaq. [œs œtsu uryrtoː eneːim kœːsjoh βyl eneːim aːireɐɸ lixpjuːaʔ] ęs ętsu ur-ųrt-ō enēim kę̄sy-oh bhųl enēim āir-eᵃph lichp-y-ūaq RDP-sit-PFCT:IND:1SG rock-ACC 1PL-ACC rain-V-IMPF:IND:IMPR ‘sat rock, raining .’","code":""},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"r-code-chunk","dir":"Articles","previous_headings":"Include interlinear glosses","what":"R code chunk","title":"Typesetting interlinear glosses","text":"Alternatively, one can use R code chunk set results='asis'. Ksǫnteziṇ gartosesī ōroi Vāisi su Meukha su vēsyēl selo ellāimōma enēim āireᵃph. [ksɵnteziŋ gartosesiː oːroi vaːisi su meuxa su veːsjeːl selo ellaːimoːma eneːim aːreɐɸ] ksǫntez-̣ garto-se-sī ōroi Vāisi su Meucha su vēsy-ēl sel-o ellāim-ōma enēim āir-eᵃph pleasure-INST tell-1SG-2PL:ACC sun:NOM moon:NOM star-NOM:PL -3PL:ABS 1PL-ACC ‘pleasure tell Sun, Moon stars us.’","code":"include_gloss(eleryon, \"tx_000001\", \"st_000002\")"},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"original-writing-system-and-transcriptiontransliteration","dir":"Articles","previous_headings":"","what":"Original writing system and transcription/transliteration","title":"Typesetting interlinear glosses","text":"ふぁろっしゃ「ぎそんの「うっつろい Farossha gisonno uttroi. [faɽɔʃʃa gisɔnno uttɽoi] fa-rossha gi-sonno uttr-oi ACC-lunch NOM-1PL eat-1PL ‘lunch.’","code":"bromi_path <- system.file(\"extdata/bromi_lexadb\", package = \"lexa\")  bromi <- load_lexadb(bromi_path) #> ℹ Loading lexa database..."},{"path":"https://stefanocoretta.github.io/lexa/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Stefano Coretta. Author, maintainer.            stefanocoretta","code":""},{"path":"https://stefanocoretta.github.io/lexa/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Coretta S (2024). lexa: Lexicon texts database management. R package version 0.0.3,  https://stefanocoretta.github.io/lexa/, https://github.com/stefanocoretta/lexa.","code":"@Manual{,   title = {lexa: Lexicon and texts database management},   author = {Stefano Coretta},   year = {2024},   note = {R package version 0.0.3,  https://stefanocoretta.github.io/lexa/},   url = {https://github.com/stefanocoretta/lexa}, }"},{"path":"https://stefanocoretta.github.io/lexa/index.html","id":"lexa-manage-documentary-and-descriptive-linguistic-data-","dir":"","previous_headings":"","what":"Lexicon and texts database management","title":"Lexicon and texts database management","text":"goal lexa provide framework tools manage linguistic fieldwork data. package still infancy limited set features developed time . package contains highly unstable code, expect breaking changes point (although try keep minimum). current available features : Create Lexa database. Add lexical entries database. Search lexical entries word definition. Import lexical entries .csv file.","code":""},{"path":"https://stefanocoretta.github.io/lexa/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Lexicon and texts database management","text":"can install latest version lexa like :","code":"remotes::install_github(   \"stefanocoretta/lexa@v0.0.3\",   build_vignettes = TRUE )"},{"path":"https://stefanocoretta.github.io/lexa/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick start","title":"Lexicon and texts database management","text":"create new database: create directory new_lexadb/ parent directory (./). See vignette(\"database-schema\", package = \"lexa\") details. lexicon/ folder populated file entry skeleton can manually edit. create new entries first need load database: Now can add new entry : create new file entry skeleton, can edit. new id automatically created based existing files. search lexicon: can also display texts, sentences lexical entries! include interlinear glosses HTML LaTeX documents, check vignette(\"interlinear-gloss\").","code":"library(lexa)  create_lexadb(   parent = \"./\",   name = \"new\" ) new_db <- load_lexadb(\"./new_lexadb\")  new_db add_entry(new_db) db_path <- system.file(\"extdata/eleryon_lexadb\", package = \"lexa\") eleryon <- load_lexadb(db_path) #> ℹ Loading lexa database... eleryon #>  #> ── Database info ─────────────────────────────────────────────────────────────── #> ◉ Name: eleryon #> ℹ Entries: 6 | Texts: 1 #>  #> ── Lexicon breakdown ── #>  #> ◉ Categories → Lexical: 6 #> ◉ Morpheme types → Roots: 6 #> ◉ POS → Adverbs: 1 | Nouns: 1 | Verbs: 4  search_lexicon(eleryon, entry = \"unullose\") #> ✔ Found 1 entry. #>  #> ── Entry lx_000002 ───────────────────────────────────────────────────────────── #> unullose [unullose] verb (IV) #>  #> ── Senses ── #>  #> 1. to love #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • nul [nul] #> • unul [unul] search_lexicon(eleryon, definition = \"tomorrow\") #> ✔ Found 1 entry. #>  #> ── Entry lx_000005 ───────────────────────────────────────────────────────────── #> chǭs [tʃɵːs] adverb #>  #> ── Senses ── #>  #> 1. tomorrow #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • chǭs [tʃɵːs] #>  #> ── Notes ── #>  #> • Note that in Eleryon this word means 'tomorrow' if used by noon, otherwise it #> means 'the day after tomorrow'. show_text(eleryon, 1) #>  #> ── Example sentences ─────────────────────────────────────────────────────────── #>  #> ── st_000001 ── #>  #> Ęs ętsu urųrtō enēim kę̄syoh bhųl enēim āireᵃph likhpyūaq. #> And then I sat on a rock, while it was raining over me. #>  #> ── st_000002 ── #>  #> Ksǫnteziṇ gartosesī ōroi Vāisi su Meukha su vēsyēl selo ellāimōma enēim #> āireᵃph. #> With pleasure I tell you about the Sun, the Moon and the stars that are above #> us.  show_entry(eleryon, 6) #>  #> ── Entry lx_000006 ───────────────────────────────────────────────────────────── #> urųrtose [uryrtose] verb (I) #>  #> ── Senses ── #>  #> 1. to sit #>  #>           ── Examples #>           Ęs ętsu urųrtō enēim kę̄syoh bhųl enēim āireᵃph likhpyūaq. #>           [tx_000001:st_000001] #>           And then I sat on a rock, while it was raining over me. #>  #>           Ksǫnteziṇ gartosesī ōroi Vāisi su Meukha su vēsyēl selo ellāimōma #>           enēim āireᵃph. [tx_000001:st_000002] #>           With pleasure I tell you about the Sun, the Moon and the stars that #>           are above us. #>  #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • ųrt [yrt] #> • urųrt [uryrt]"},{"path":"https://stefanocoretta.github.io/lexa/reference/add_entry.html","id":null,"dir":"Reference","previous_headings":"","what":"Add entry to lexicon — add_entry","title":"Add entry to lexicon — add_entry","text":"function creates new entry lexicon, .e. new empty entry skeleton written disk, lexicon/ directory, user edit .","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/add_entry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add entry to lexicon — add_entry","text":"","code":"add_entry(   lexadb,   entry = NULL,   gloss = NULL,   part_of_speech = NULL,   phon = NULL,   morph_category = NULL,   morph_type = NULL,   definition = gloss,   etymology = NULL,   notes = NULL )"},{"path":"https://stefanocoretta.github.io/lexa/reference/add_entry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add entry to lexicon — add_entry","text":"lexadb lexadb object (created load_lexadb). entry entry string. gloss gloss string. part_of_speech part speech string. phon phonetic transcription string. morph_category morphosyntactic category string (\"lexical\" \"grammatical\"). morph_type type morpheme string. definition definition entry string. etymology etymology entry string. notes notes string.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/add_entry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add entry to lexicon — add_entry","text":"Nothing. Used side effects","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/add_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Add text to database — add_text","title":"Add text to database — add_text","text":"function creates new text database, .e. new empty text skeleton written disk, texts/ directory, user edit .","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/add_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add text to database — add_text","text":"","code":"add_text(lexadb, title = NULL)"},{"path":"https://stefanocoretta.github.io/lexa/reference/add_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add text to database — add_text","text":"lexadb lexadb object (created load_lexadb) title text title string.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/add_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add text to database — add_text","text":"Nothing. Used side effects","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/create_lexadb.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new Lexa database — create_lexadb","title":"Create a new Lexa database — create_lexadb","text":"Create new Lexa database","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/create_lexadb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new Lexa database — create_lexadb","text":"","code":"create_lexadb(parent = \".\", name)"},{"path":"https://stefanocoretta.github.io/lexa/reference/create_lexadb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new Lexa database — create_lexadb","text":"parent Parent directory (default current working directory). name Name Lexa database (_lexadb appended name).","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/create_lexadb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new Lexa database — create_lexadb","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/create_lexadb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a new Lexa database — create_lexadb","text":"","code":"if (FALSE) { create_lexadb(parent = \"./\", name = \"my_new\") }"},{"path":"https://stefanocoretta.github.io/lexa/reference/import_lexicon_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Import lexicon from a csv file — import_lexicon_csv","title":"Import lexicon from a csv file — import_lexicon_csv","text":"imports entries .csv file lexical data. file must specific columns, see Details file specifics. lexicon imported existing Lexa database.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/import_lexicon_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import lexicon from a csv file — import_lexicon_csv","text":"","code":"import_lexicon_csv(lexadb, path)"},{"path":"https://stefanocoretta.github.io/lexa/reference/import_lexicon_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import lexicon from a csv file — import_lexicon_csv","text":"lexadb lexadb object returned load_lexadb(). path path lexicon .csv file string.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/import_lexicon_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import lexicon from a csv file — import_lexicon_csv","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/import_lexicon_csv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import lexicon from a csv file — import_lexicon_csv","text":"file must least following columns: entry: lexical entry, appear head entry. gloss: gloss entry. Optionally, file can following columns: definition: full definition entry. normally provides details meaning gloss. column present, definition field filled gloss. phon: phonetic transcription entry. morph_category: category entry (e.g. lexical vs grammatical). morph_type: type morpheme (e.g. root vs affix). part_of_speech: part speech entry. class: lexical class entry (e.g. verbal conjugations, noun classes). etymology: etymology entry. notes: free text notes. Note list temporary change future.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/include_gloss.html","id":null,"dir":"Reference","previous_headings":"","what":"Include gloss in Rmd — include_gloss","title":"Include gloss in Rmd — include_gloss","text":"See vignette(\"interlinear-gloss\") usage.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/include_gloss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Include gloss in Rmd — include_gloss","text":"","code":"include_gloss(...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/include_gloss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Include gloss in Rmd — include_gloss","text":"... Arguments passed print_gloss().","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa-package.html","id":null,"dir":"Reference","previous_headings":"","what":"lexa: Lexicon and texts database management — lexa-package","title":"lexa: Lexicon and texts database management — lexa-package","text":"provides database schema functions manage language database made lexicon collection texts.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"lexa: Lexicon and texts database management — lexa-package","text":"Maintainer: Stefano Coretta stefano.coretta@gmail.com (ORCID) (stefanocoretta)","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_html.html","id":null,"dir":"Reference","previous_headings":"","what":"Lexa HTML document — lexa_html","title":"Lexa HTML document — lexa_html","text":"custom Rmarkdown template typeset HTML documents extra support interlinear glosses. # nolint","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_html.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lexa HTML document — lexa_html","text":"","code":"lexa_html(...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_html.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lexa HTML document — lexa_html","text":"... Arguments passed html_document.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_pdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Lexa PDF document — lexa_pdf","title":"Lexa PDF document — lexa_pdf","text":"custom Rmarkdown template typeset PDF documents extra support interlinear glosses. Note format uses custom Pandoc LaTeX template, incompatibilities bewteen expex unicode-math.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_pdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lexa PDF document — lexa_pdf","text":"","code":"lexa_pdf(...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_pdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lexa PDF document — lexa_pdf","text":"... Arguments passed pdf_document.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/load_lexadb.html","id":null,"dir":"Reference","previous_headings":"","what":"Load Lexa database — load_lexadb","title":"Load Lexa database — load_lexadb","text":"loadds Lexa database specified path. path directory containing database.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/load_lexadb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load Lexa database — load_lexadb","text":"","code":"load_lexadb(path)"},{"path":"https://stefanocoretta.github.io/lexa/reference/load_lexadb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load Lexa database — load_lexadb","text":"path path database string.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/load_lexadb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load Lexa database — load_lexadb","text":"lexadb object.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/load_lexadb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Load Lexa database — load_lexadb","text":"","code":"db_path <- system.file(\"extdata/albanian_lexadb\", package = \"lexa\") albanian <- load_lexadb(db_path) #> ℹ Loading lexa database... albanian #>  #> ── Database info ─────────────────────────────────────────────────────────────── #> ◉ Name: albanian #> ℹ Entries: 0 | Texts: 1 #>  #> ── Lexicon breakdown ── #>  #> ◉ Categories → #> ◉ Morpheme types → #> ◉ POS →"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexadb.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for Lexa databases — print.lexadb","title":"Print method for Lexa databases — print.lexadb","text":"Print method objects class lexadb, prints database info statistics.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexadb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for Lexa databases — print.lexadb","text":"","code":"# S3 method for lexadb print(x, ...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexadb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for Lexa databases — print.lexadb","text":"x object class lexadb. ... Arguments passed print.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexadb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for Lexa databases — print.lexadb","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalx.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for lexemes — print.lexalx","title":"Print method for lexemes — print.lexalx","text":"Print method objects class lexalx, prints lexeme info.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for lexemes — print.lexalx","text":"","code":"# S3 method for lexalx print(x, ...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for lexemes — print.lexalx","text":"x object class lexalx. ... Arguments passed print.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for lexemes — print.lexalx","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalxs.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for list of entries — print.lexalxs","title":"Print method for list of entries — print.lexalxs","text":"Print method output search_lexicon(), returns object class lexalxs.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalxs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for list of entries — print.lexalxs","text":"","code":"# S3 method for lexalxs print(x, ...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalxs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for list of entries — print.lexalxs","text":"x object class lexalxs. ... Arguments passed print.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalxs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for list of entries — print.lexalxs","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexast.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for sentences — print.lexast","title":"Print method for sentences — print.lexast","text":"Print method objects class lexast, prints text sentences.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for sentences — print.lexast","text":"","code":"# S3 method for lexast print(x, ...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for sentences — print.lexast","text":"x object class lexast. ... Arguments passed print.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for sentences — print.lexast","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexatx.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for texts — print.lexatx","title":"Print method for texts — print.lexatx","text":"Print method objects class lexatx, prints text info.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexatx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for texts — print.lexatx","text":"","code":"# S3 method for lexatx print(x, ...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexatx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for texts — print.lexatx","text":"x object class lexatx. ... Arguments passed print.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexatx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for texts — print.lexatx","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_lexicon.html","id":null,"dir":"Reference","previous_headings":"","what":"Search lexicon entries — search_lexicon","title":"Search lexicon entries — search_lexicon","text":"Search entries lexicon, entry form sense definitions.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_lexicon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search lexicon entries — search_lexicon","text":"","code":"search_lexicon(   lexadb,   entry = NULL,   whole = TRUE,   definition = NULL,   pos = NULL )"},{"path":"https://stefanocoretta.github.io/lexa/reference/search_lexicon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search lexicon entries — search_lexicon","text":"lexadb lexadb object (created load_lexadb). entry regular expression search among entries. whole Whether search whole words (applies entry, TRUE default). definition regular expression search among sense definitions. pos regular expression match part speech.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_lexicon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search lexicon entries — search_lexicon","text":"list lexalx objects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_lexicon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search lexicon entries — search_lexicon","text":"","code":"db_path <- system.file(\"extdata/eleryon_lexadb\", package = \"lexa\") eleryon <- load_lexadb(db_path) #> ℹ Loading lexa database...  # Search for \"chǭs\" search_lexicon(eleryon, \"chǭs\") #> ✔ Found 1 entry. #>  #> ── Entry lx_000005 ───────────────────────────────────────────────────────────── #> chǭs [tʃɵːs] adverb #>  #> ── Senses ── #>  #> 1. tomorrow #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • chǭs [tʃɵːs] #>  #> ── Notes ── #>  #> • Note that in Eleryon this word means 'tomorrow' if used by noon, otherwise it #> means 'the day after tomorrow'.  # Search for all verbs search_lexicon(eleryon, \".*\", pos = \"verb\") #> ✔ Found 5 entries. #>  #> ── Entry lx_000002 ───────────────────────────────────────────────────────────── #> unullose [unullose] verb (IV) #>  #> ── Senses ── #>  #> 1. to love #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • nul [nul] #> • unul [unul] #>  #> ── Entry lx_000003 ───────────────────────────────────────────────────────────── #> vēselse [veɪselse] verb (II) #>  #> ── Senses ── #>  #> 1. to understand #> 2. to learn #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • vēsel [veɪsel] #>  #> ── Entry lx_000004 ───────────────────────────────────────────────────────────── #> evēsellose [eveɪsellose] verb (IV) #>  #> ── Senses ── #>  #> 1. to teach #>  #> ── Etymology ── #>  #> From vēselse 'to learn'. #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • vēsel [veɪsel] #> • evēsel [eveɪsel] #>  #> ── Entry lx_000005 ───────────────────────────────────────────────────────────── #> chǭs [tʃɵːs] adverb #>  #> ── Senses ── #>  #> 1. tomorrow #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • chǭs [tʃɵːs] #>  #> ── Notes ── #>  #> • Note that in Eleryon this word means 'tomorrow' if used by noon, otherwise it #> means 'the day after tomorrow'. #>  #> ── Entry lx_000006 ───────────────────────────────────────────────────────────── #> urųrtose [uryrtose] verb (I) #>  #> ── Senses ── #>  #> 1. to sit #>  #>           ── Examples  #>           Ęs ętsu urųrtō enēim kę̄syoh bhųl enēim āireᵃph likhpyūaq. [tx #>           000001:st_000001] #>           And then I sat on a rock, while it was raining over me. #>            #>           Ksǫnteziṇ gartosesī ōroi Vāisi su Meukha su vēsyēl selo ellāimōma e #>           ēim āireᵃph. [tx_000001:st_000002] #>           With pleasure I tell you about the Sun, the Moon and the stars that #>           are above us. #>            #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • ųrt [yrt] #> • urųrt [uryrt]  # Search for entry with meaning \"love\" search_lexicon(eleryon, definition = \"love\") #> ✔ Found 1 entry. #>  #> ── Entry lx_000002 ───────────────────────────────────────────────────────────── #> unullose [unullose] verb (IV) #>  #> ── Senses ── #>  #> 1. to love #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • nul [nul] #> • unul [unul]"},{"path":"https://stefanocoretta.github.io/lexa/reference/search_texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Search words in texts — search_texts","title":"Search words in texts — search_texts","text":"Search words texts collection.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search words in texts — search_texts","text":"","code":"search_texts(lexadb, word = NULL, whole = TRUE, gloss = NULL)"},{"path":"https://stefanocoretta.github.io/lexa/reference/search_texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search words in texts — search_texts","text":"lexadb lexadb object (created load_lexadb). word regular expression search among sentences. whole Whether search whole words (TRUE default). gloss regular expression search among glosses.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search words in texts — search_texts","text":"list lexalx objects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_texts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Search words in texts — search_texts","text":"","code":"db_path <- system.file(\"extdata/albanian_lexadb\", package = \"lexa\") albanian <- load_lexadb(db_path) #> ℹ Loading lexa database...  search_texts(albanian, \"rrezet\") #> ℹ Found 1 matches. #> $tx_000001 #>  #> ── The North Wind and the Sun ────────────────────────────────────────────────── #>  #> ── st_000007 ── #>  #> Pastaj Dielli lëshoi rrezet e tij të ngrohta dhe menjëherë udhëtari e hoqi #> pallton. #> Then the Sun released his warm rays and immediately the traveller took off his #> cloak. #>  search_texts(albanian, gloss = \"sun\") #> ℹ Found 3 matches. #> $tx_000001 #>  #> ── The North Wind and the Sun ────────────────────────────────────────────────── #>  #> ── st_000001 ── #>  #> Era e Veriut dhe Dielli po ziheshin se kush ishte më i fortë. #> The North Wind and the Sun were disputing which was the stronger, #>  #> ── st_000007 ── #>  #> Pastaj Dielli lëshoi rrezet e tij të ngrohta dhe menjëherë udhëtari e hoqi #> pallton. #> Then the Sun released his warm rays and immediately the traveller took off his #> cloak. #>  #> ── st_000008 ── #>  #> E kështu Era e Veriut u detyrua të pranonte që Dielli ishte më i fortë se ajo. #> And so the North Wind was forced to accept that the Sun was the stronger than #> itself. #>  search_texts(albanian, gloss = \"traveller\") #> ℹ Found 4 matches. #> $tx_000001 #>  #> ── The North Wind and the Sun ────────────────────────────────────────────────── #>  #> ── st_000002 ── #>  #> Kur aty kaloi një udhëtar që kishte veshur një pallto të ngrohtë. #> when a traveller came along wrapped in a warm cloak. #>  #> ── st_000003 ── #>  #> Ata ranë dakord që kush do ta bënte udhëtarin të hiqte pallton më përpara do të #> quhej më i forti. #> They agreed that the one who first succeeded in making the traveller take his #> cloak off first should be considered the stronger one. #>  #> ── st_000005 ── #>  #> por sa më shumë që frynte aq më shumë kapej udhëtari pas palltos së tij, #> but the more he blew the more closely did the traveller fold his cloak around #> him, #>  #> ── st_000007 ── #>  #> Pastaj Dielli lëshoi rrezet e tij të ngrohta dhe menjëherë udhëtari e hoqi #> pallton. #> Then the Sun released his warm rays and immediately the traveller took off his #> cloak. #>"},{"path":"https://stefanocoretta.github.io/lexa/reference/show_entry.html","id":null,"dir":"Reference","previous_headings":"","what":"Show lexicon entry with given id — show_entry","title":"Show lexicon entry with given id — show_entry","text":"shows entry given id.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_entry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show lexicon entry with given id — show_entry","text":"","code":"show_entry(lexadb, entry_id)"},{"path":"https://stefanocoretta.github.io/lexa/reference/show_entry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show lexicon entry with given id — show_entry","text":"lexadb lexadb object (created load_lexadb). entry_id string entry id (lx_ prefix leading zeros can omitted.)","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_entry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show lexicon entry with given id — show_entry","text":"lexalx object.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_entry.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show lexicon entry with given id — show_entry","text":"","code":"db_path <- system.file(\"extdata/eleryon_lexadb\", package = \"lexa\") eleryon <- load_lexadb(db_path) #> ℹ Loading lexa database...  show_entry(eleryon, 6) #>  #> ── Entry lx_000006 ───────────────────────────────────────────────────────────── #> urųrtose [uryrtose] verb (I) #>  #> ── Senses ── #>  #> 1. to sit #>  #>           ── Examples  #>           Ęs ętsu urųrtō enēim kę̄syoh bhųl enēim āireᵃph likhpyūaq. [tx #>           000001:st_000001] #>           And then I sat on a rock, while it was raining over me. #>            #>           Ksǫnteziṇ gartosesī ōroi Vāisi su Meukha su vēsyēl selo ellāimōma e #>           ēim āireᵃph. [tx_000001:st_000002] #>           With pleasure I tell you about the Sun, the Moon and the stars that #>           are above us. #>            #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • ųrt [yrt] #> • urųrt [uryrt] # Same as: show_entry(eleryon, \"lx_000006\") #>  #> ── Entry lx_000006 ───────────────────────────────────────────────────────────── #> urųrtose [uryrtose] verb (I) #>  #> ── Senses ── #>  #> 1. to sit #>  #>           ── Examples  #>           Ęs ętsu urųrtō enēim kę̄syoh bhųl enēim āireᵃph likhpyūaq. [tx #>           000001:st_000001] #>           And then I sat on a rock, while it was raining over me. #>            #>           Ksǫnteziṇ gartosesī ōroi Vāisi su Meukha su vēsyēl selo ellāimōma e #>           ēim āireᵃph. [tx_000001:st_000002] #>           With pleasure I tell you about the Sun, the Moon and the stars that #>           are above us. #>            #>  #> ── Grammatical info ── #>  #> Category: lexical #> Type: root #>  #> ── Allomorphs ── #>  #> • ųrt [yrt] #> • urųrt [uryrt]"},{"path":"https://stefanocoretta.github.io/lexa/reference/show_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Show text or sentence with given id — show_text","title":"Show text or sentence with given id — show_text","text":"shows text sentence given id.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show text or sentence with given id — show_text","text":"","code":"show_text(lexadb, text_id, sent_id = NULL)"},{"path":"https://stefanocoretta.github.io/lexa/reference/show_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show text or sentence with given id — show_text","text":"lexadb lexadb object (created load_lexadb). text_id string text id (tx_ prefix leading zeros can omitted.) sent_id string sentence id (st_ prefix leading zeros can omitted.)","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show text or sentence with given id — show_text","text":"lexast object.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_text.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Show text or sentence with given id — show_text","text":"","code":"db_path <- system.file(\"extdata/albanian_lexadb\", package = \"lexa\") albanian <- load_lexadb(db_path) #> ℹ Loading lexa database...  show_text(albanian, 1) #>  #> ── The North Wind and the Sun ────────────────────────────────────────────────── #>  #> ── st_000001 ── #>  #> Era e Veriut dhe Dielli po ziheshin se kush ishte më i fortë. #> The North Wind and the Sun were disputing which was the stronger, #>  #> ── st_000002 ── #>  #> Kur aty kaloi një udhëtar që kishte veshur një pallto të ngrohtë. #> when a traveller came along wrapped in a warm cloak. #>  #> ── st_000003 ── #>  #> Ata ranë dakord që kush do ta bënte udhëtarin të hiqte pallton më përpara do të #> quhej më i forti. #> They agreed that the one who first succeeded in making the traveller take his #> cloak off first should be considered the stronger one. #>  #> ── st_000004 ── #>  #> Fill pas kësaj, Era e Veriut filloi të frynte me gjithë fuqinë e saj, #> Then the North Wind blew as hard as he could, #>  #> ── st_000005 ── #>  #> por sa më shumë që frynte aq më shumë kapej udhëtari pas palltos së tij, #> but the more he blew the more closely did the traveller fold his cloak around #> him, #>  #> ── st_000006 ── #>  #> derisa më në fund Era e Veriut u dorëzua. #> and at last the North Wind gave up the attempt. #>  #> ── st_000007 ── #>  #> Pastaj Dielli lëshoi rrezet e tij të ngrohta dhe menjëherë udhëtari e hoqi #> pallton. #> Then the Sun released his warm rays and immediately the traveller took off his #> cloak. #>  #> ── st_000008 ── #>  #> E kështu Era e Veriut u detyrua të pranonte që Dielli ishte më i fortë se ajo. #> And so the North Wind was forced to accept that the Sun was the stronger than #> itself. show_text(albanian, 1, 3) #>  #> ── Ata ranë dakord që kush do ta bënte udhëtarin të hiqte pallton më përpara do  #> [ata ɽanɜ dakɔɽd | t̻ʃ̻ɜ kuʃ dɔ ta bɜnte uðɜtaɽin tɜ hit̻ʃ̻te palˠtɔn mɜ pɜɽpaɽa dɔ #> tɜ t̻ʃ̻uhej mɜ i fɔɽti ‖] #>  #> ata         ra-në                  dakord      që     kush   do    t=a            #> 3PL.M.NOM   AOR\\fall-AOR.IND.3PL   agreement   that   who    Fut   Fut=3SG.ACC    #>  #> bën-te              udhëtar-in               të     hiq-te                        #> make-IND.IMPF.3SG   traveller-M.SG.ACC.DEF   SBJV   SBJV\\take_off-PST.SBJV.3SG    #>  #> pallt-on            më     përpara   do    të    quh-ej                   më      #> coat-F.SG.ACC.DEF   more   soon      Fut   Fut   PASS\\call-IMPF.IND.3SG   more    #>  #> i              fort-i                 #> M.SG.NOM.DEF   strong-M.SG.NOM.DEF    #>  #>  #> ‘They agreed that the one who first succeeded in making the traveller take his #> cloak off first should be considered the stronger one.’"},{"path":"https://stefanocoretta.github.io/lexa/reference/typeset_gloss.html","id":null,"dir":"Reference","previous_headings":"","what":"Typeset interlinear gloss — typeset_gloss","title":"Typeset interlinear gloss — typeset_gloss","text":"function returns selected sentence properly formatted html/latex code.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/typeset_gloss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Typeset interlinear gloss — typeset_gloss","text":"","code":"typeset_gloss(lexadb, text, sentence, format = \"latex\")"},{"path":"https://stefanocoretta.github.io/lexa/reference/typeset_gloss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Typeset interlinear gloss — typeset_gloss","text":"lexadb lexadb object (created load_lexadb). text Text id. sentence Sentence id print. format Format print (either html latex).","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/typeset_gloss.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Typeset interlinear gloss — typeset_gloss","text":"","code":"db_path <- system.file(\"extdata/albanian_lexadb\", package = \"lexa\") albanian <- load_lexadb(db_path) #> ℹ Loading lexa database...  typeset_gloss(albanian, 1, 1) #> ```{=latex} #> \\ex \\begingl #> \\glpreamble Era e Veriut dhe Dielli po ziheshin se kush ishte më i fortë.// #> \\glpreamble [eɽa e veɽiut | ðe dielˠi | pɔ ziheʃin se kuʃ iʃte mɜ i fɔɽtɜ ‖]// #> \\gla er-a e ver-iut  dhe diell-i  po zihe-shin se kush ishte më i fort-ë// #> \\glb wind-\\F{}.\\Sg{}.\\Nom{}.\\Def{} \\F{}.\\Sg{}.\\Gen{}.\\Def{} north-\\M{}.\\Sg{}.\\Gen{}.\\Def{}  and sun-\\M{}.\\Sg{}.\\Nom{}.\\Def{}  \\Prog{} fight-\\Impf{}.\\Ind{}.3\\Pl{} that who be.\\Impf{}.\\Ind{}.3\\Sg{} more \\M{}.\\Sg{}.\\Acc{}.\\Def{} strong-\\M{}.\\Sg{}.\\Acc{}.\\Def{}// #> \\glft `The North Wind and the Sun were disputing which was the stronger,'// #> \\endgl \\xe #> ``` typeset_gloss(albanian, 1, 1, format = \"html\") #> <div data-gloss> #>   <p class=\"gloss__line--original\">Era e Veriut dhe Dielli po ziheshin se kush ishte më i fortë.<\/p> #>   <p class=\"gloss__line--original\" style=\"font-weight: 400;\">[eɽa e veɽiut | ðe dielˠi | pɔ ziheʃin se kuʃ iʃte mɜ i fɔɽtɜ ‖]<\/p> #>   <p>er-a e ver-iut  dhe diell-i  po zihe-shin se kush ishte më i fort-ë<\/p> #>   <p>wind-F.SG.NOM.DEF F.SG.GEN.DEF north-M.SG.GEN.DEF  and sun-M.SG.NOM.DEF  PROG fight-IMPF.IND.3PL that who be.IMPF.IND.3SG more M.SG.ACC.DEF strong-M.SG.ACC.DEF<\/p> #>   <p>‘The North Wind and the Sun were disputing which was the stronger,’<\/p> #> <\/div>"},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"added-0-0-3","dir":"Changelog","previous_headings":"","what":"Added","title":"lexa 0.0.3","text":"add_text() outputs empty text skeleton.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"changed-0-0-3","dir":"Changelog","previous_headings":"","what":"Changed","title":"lexa 0.0.3","text":"Fixed errors Eleryon database.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"added-0-0-2","dir":"Changelog","previous_headings":"","what":"Added","title":"lexa 0.0.2","text":"🎉 New logo! New lexa database bromi_lexadb. Support non-Latin based writing systems.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"changed-0-0-2","dir":"Changelog","previous_headings":"","what":"Changed","title":"lexa 0.0.2","text":"Specification texts now include transcription transliteration. Print method lexatx lexasc now include transcription/transliteration. Typeset gloss includes transcription/transliteration.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"added-0-0-1","dir":"Changelog","previous_headings":"","what":"Added","title":"lexa 0.0.1","text":"show_text() show text/sentence based ID.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-1","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.1","text":"Errors importing lexicon csv file. Check presence lexical information printing database, print nothing present. create_lexadb() now creates empty skeleton text.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-0-9006","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.0.9006","text":"Gloss translation PDF output includes quotes.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-0-9005","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.0.9005","text":"Fix error lexa_pdf using bookdown base_format. Underscores glosses now converted \\textunderscore output PDF.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"changed-0-0-0-9005","dir":"Changelog","previous_headings":"","what":"Changed","title":"lexa 0.0.0.9005","text":"typeset_gloss() supports numeric text sentence ID. typeset_gloss() now outputs gloss abbreviations leipzig commands output format PDF. Improved lexa_pdf Rmarkdown template: Using custom LaTeX template circumvent unicode-math incompatibility expex leipzig. Includes list abbreviations glosses leipzig commands (list based Croft Tyopology Universals).","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-0-9004","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.0.9004","text":"Error typeset_gloss() phon present latex format.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-0-9003","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.0.9003","text":"typeset_gloss() returning latex gloss phonetic transcription present.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"breaking-changes-0-0-0-9002","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"lexa 0.0.0.9002","text":"Renamed import_lexicon() import_lexicon_csv(). create_entry() longer exported. Renamed print_gloss() typeset_gloss().","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"added-0-0-0-9002","dir":"Changelog","previous_headings":"","what":"Added","title":"lexa 0.0.0.9002","text":"search_lexicon() adds pos argument filter part speech. print method lexadb also includes lexicon breakdown numerical summaries. print method lexalx also prints allomorph information , present, examples, etymology notes. lexicon entry schema now following fields: loan_word, crossref, variants, semantics (semantic_domain, synonyms, antonyms), (added senses) literal, scientific usage. Print methods lexatx lexast. Print method lexalxs (returned search_lexicon()). Added albanian database. search_texts() search words glosses texts. show_entry() prints entry given entry_id. Custom RMarkdown templates lexa_pdf lexa_html.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"changed-0-0-0-9002","dir":"Changelog","previous_headings":"","what":"Changed","title":"lexa 0.0.0.9002","text":"create_entry() now exported outputs list entry id string containing entry skeleton. create_entry() now allows user specify values entry fields. add_entry() now passes arguments create_entry() user can specify fields. entry senses now numbered printed. Changed texts schema. search_lexicon() search_texts() now search whole words default. can changed specifying whole = FALSE. lexalx printing method improved.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-0-9002","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.0.9002","text":"Printing interlinear glosses now works even repeated spaces words.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"lexa-0009001","dir":"Changelog","previous_headings":"","what":"lexa 0.0.0.9001","title":"lexa 0.0.0.9001","text":"First beta release.","code":""}]
