[{"path":"https://stefanocoretta.github.io/lexa/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 Stefano Coretta Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://stefanocoretta.github.io/lexa/articles/database-schema.html","id":"general-structure","dir":"Articles","previous_headings":"","what":"General structure","title":"Lexa Database Schema","text":"Lexa database (lexadb) directory containing following files/dirs: config.yaml: database configuration file. grammar.yaml: grammar specification file. lexicon/: directory containing Lexa lexicon files. texts/: directory containing Lexa text collections (lexatxt).","code":""},{"path":"https://stefanocoretta.github.io/lexa/articles/database-schema.html","id":"lexicon-file","dir":"Articles","previous_headings":"","what":"Lexicon file","title":"Lexa Database Schema","text":"","code":"id: lx_00000n lexeme: <string> phon: <string> morph_category: <lexical, grammatical> morph_type: <root, stem, affix, clitic, particle, compound, phrase> part_of_speech: <string> inflectional_features:   <feature_n>: <string> etymology: <string> loan_word: <string> notes: [<string>] allomorphs:   al_0n:     id: al_0n     morph: <string>     phon: <string>     conditioning:       type: <phonological, morphosyntactic, free>       context: <string> senses:   se_0n:     id: se_0n     gloss: <string>     definition: <string>     literal: <string>     scientific: <string>     usage: <string>     inflectional_features:       <feature_n>: <string>     examples: [\"tx_00000n:st_00000n\"]     etymology: <string> crossref: [\"lx_00000n\"] variants: [<string>] semantics:   semantic_domain: [\"sd_00000n\"]   synonyms: [\"lx_00000n\"]   antonyms: [\"lx_00000n\"] date_created: <date> date_modified: <date>"},{"path":"https://stefanocoretta.github.io/lexa/articles/database-schema.html","id":"text-collection","dir":"Articles","previous_headings":"","what":"Text collection","title":"Lexa Database Schema","text":"Texts located texts/ folder. text saved separate .yaml file, restrictions naming (except must avoid spaces fancy characters.)","code":"id: tx_00000n title: <string> topic: <string> genre: <string> participants: [<string>] translators: [<string>] source: <string> sentences:   st_00000n:     sentence: <string>     phon: <string>     morpho_phon: <string>     morpho: <string>     gloss: <string>     translation: <string>     literal: <string>     notes: [<string>] notes: [<string>]"},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Typesetting interlinear glosses","text":"Users can output interlinear glosses Rmarkdown files texts Lexa database. PDF HTML output formats supported. LaTeX package expex used PDF output, HTML glosses rendered Leipzig.js. time, functionalities implemented within lexa limited, provide sufficient coverage basic glossing.","code":""},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"load-a-lexa-database","dir":"Articles","previous_headings":"","what":"Load a Lexa database","title":"Typesetting interlinear glosses","text":"load Lexa database, first attach lexa package. load example database eleryon_lexadb. can now inspect content eleryon database.","code":"library(lexa) eleryon_path <- system.file(\"extdata/eleryon_lexadb\", package = \"lexa\")  eleryon <- load_lexadb(eleryon_path) #> ℹ Loading lexa database... eleryon #>  #> ── Database info ─────────────────────────────────────────────────────────────── #> ◉ Name: eleryon #> ℹ Entries: 6 | Texts: 1 #>  #> ── Lexicon breakdown ── #>  #> ◉ Categories → Lexical: 6 #> ◉ Morpheme types → Roots: 6 #> ◉ POS → Adverbs: 1 | Nouns: 1 | Verbs: 4"},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"include-interlinear-glosses","dir":"Articles","previous_headings":"","what":"Include interlinear glosses","title":"Typesetting interlinear glosses","text":"two ways including interlinear gloss Rmarkdown file.","code":""},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"inline-r-code","dir":"Articles","previous_headings":"Include interlinear glosses","what":"Inline R code","title":"Typesetting interlinear glosses","text":"One using inline R code (see source vignette code). Ęs ętsu urųrtō enēim kę̄syoh bhųl enēim āireᵃph lichpyūaq. [œs œtsu uryrtoː eneːim kœːsjoh βyl eneːim aːireɐɸ lixpjuːaʔ] ęs ętsu ur-ųrt-ō enēim kę̄sy-oh bhųl enēim āir-eᵃph lichp-y-ūaq RDP-sit-PFCT:IND:1sg rock-ACC 1pl-ACC rain-CL5-IMPF:IND:IMPR ‘sat rock, raining .’","code":""},{"path":"https://stefanocoretta.github.io/lexa/articles/interlinear-gloss.html","id":"r-code-chunk","dir":"Articles","previous_headings":"Include interlinear glosses","what":"R code chunk","title":"Typesetting interlinear glosses","text":"Alternatively, one can use R code chunk set results='asis'. Ksǫnteziṇ gartosesī ōroi Vāisi su Meucha su vēsyēl selo ellāimōma enēim āireᵃph. [ksɵnteziŋ gartosesiː oːroi vaːisi su meuxa su veːsjeːl selo ellaːimoːma eneːim aːreɐɸ] ksǫntez-̣ garto-se-sī ōroi Vāisi su Meucha su vēsy-ēl sel-o ellāim-ōma enēim āir-eᵃph pleasure-??? tell-1sg-??? sun:NOM moon:NOM star-NOM:PL -3pl:ABS 1pl-ACC ‘pleasure tell Sun, Moon stars us.’","code":"include_gloss(eleryon, \"tx_000001\", \"st_000002\")"},{"path":"https://stefanocoretta.github.io/lexa/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Stefano Coretta. Author, maintainer.            stefanocoretta","code":""},{"path":"https://stefanocoretta.github.io/lexa/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Coretta S (2022). lexa: Lexicon texts database management. https://github.com/stefanocoretta/lexa, https://stefanocoretta.github.io/lexa/.","code":"@Manual{,   title = {lexa: Lexicon and texts database management},   author = {Stefano Coretta},   year = {2022},   note = {https://github.com/stefanocoretta/lexa, https://stefanocoretta.github.io/lexa/}, }"},{"path":"https://stefanocoretta.github.io/lexa/index.html","id":"lexa-manage-documentary-and-descriptive-linguistic-data","dir":"","previous_headings":"","what":"Lexicon and texts database management","title":"Lexicon and texts database management","text":"goal lexa provide framework tools manage linguistic fieldwork data. package still infancy limited set features developed time . package contains highly unstable code, expect breaking changes point (although try keep minimum). current available features : Create Lexa database. Add lexical entries database. Search lexical entries word definition. Import lexical entries .csv file.","code":""},{"path":"https://stefanocoretta.github.io/lexa/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Lexicon and texts database management","text":"can install latest version lexa like :","code":"remotes::install_github(   \"stefanocoretta/lexa@v0.0.1\",   build_vignettes = TRUE )"},{"path":"https://stefanocoretta.github.io/lexa/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick start","title":"Lexicon and texts database management","text":"create new database: create directory new-db_lexadb/ parent directory (./). See vignette(\"database-schema\", package = \"lexa\") details. lexicon/ folder populated file entry scheleton can manually edit. create new entries first need load database: Now can add new entry : create new file entry scheleton can edit. new id automatically created based existing files. search lexicon:","code":"library(lexa)  create_lexadb(   parent = \"./\",   name = \"new-db\" ) new_db <- load_lexadb(\"./new-db_lexadb\")  new_db add_entry(new_db) db_path <- system.file(\"extdata/eleryon_lexadb\", package = \"lexa\") eleryon <- load_lexadb(db_path) eleryon  search_lexicon(eleryon, entry = \"unullose\") search_lexicon(eleryon, definition = \"tomorrow\")"},{"path":"https://stefanocoretta.github.io/lexa/reference/add_entry.html","id":null,"dir":"Reference","previous_headings":"","what":"Add entry to lexicon — add_entry","title":"Add entry to lexicon — add_entry","text":"function creates new entry lexicon, .e. new empty entry skeleton written disk, lexicon/ directory, user edit .","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/add_entry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add entry to lexicon — add_entry","text":"","code":"add_entry(   lexadb,   entry = NULL,   gloss = NULL,   part_of_speech = NULL,   phon = NULL,   morph_category = NULL,   morph_type = NULL,   definition = gloss,   etymology = NULL,   notes = NULL )"},{"path":"https://stefanocoretta.github.io/lexa/reference/add_entry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add entry to lexicon — add_entry","text":"lexadb lexadb object (created load_lexadb). entry entry string. gloss gloss string. part_of_speech part speech string. phon phonetic transcription string. morph_category morphosyntactic category string (\"lexical\" \"grammatical\"). morph_type type morpheme string. definition definition entry string. etymology etymology entry string. notes notes string.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/add_entry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add entry to lexicon — add_entry","text":"Nothing. Used side effects","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/create_lexadb.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new Lexa database — create_lexadb","title":"Create a new Lexa database — create_lexadb","text":"Create new Lexa database","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/create_lexadb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new Lexa database — create_lexadb","text":"","code":"create_lexadb(parent = \".\", name)"},{"path":"https://stefanocoretta.github.io/lexa/reference/create_lexadb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new Lexa database — create_lexadb","text":"parent Parent directory (default current working directory). name Name Lexa database (_lexadb appended name).","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/create_lexadb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new Lexa database — create_lexadb","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/import_lexicon_csv.html","id":null,"dir":"Reference","previous_headings":"","what":"Import lexicon from a csv file — import_lexicon_csv","title":"Import lexicon from a csv file — import_lexicon_csv","text":"imports entries .csv file lexical data. file must specific columns, see Details file specifics. lexicon imported existing Lexa database.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/import_lexicon_csv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import lexicon from a csv file — import_lexicon_csv","text":"","code":"import_lexicon_csv(lexadb, path)"},{"path":"https://stefanocoretta.github.io/lexa/reference/import_lexicon_csv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import lexicon from a csv file — import_lexicon_csv","text":"lexadb lexadb object returned load_lexadb(). path path lexicon .csv file string.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/import_lexicon_csv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import lexicon from a csv file — import_lexicon_csv","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/import_lexicon_csv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Import lexicon from a csv file — import_lexicon_csv","text":"file must least following columns: entry: lexical entry, appear head entry. gloss: gloss entry. Optionally, file can following columns: definition: full definition entry. normally provides details meaning gloss. column present, definition field filled gloss. phon: phonetic transcription entry. morph_category: category entry (e.g. lexical vs grammatical). morph_type: type morpheme (e.g. root vs affix). part_of_speech: part speech entry. class: lexical class entry (e.g. verbal conjugations, noun classes). etymology: etymology entry. notes: free text notes. Note list temporary change future.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/include_gloss.html","id":null,"dir":"Reference","previous_headings":"","what":"Include gloss in Rmd — include_gloss","title":"Include gloss in Rmd — include_gloss","text":"Include gloss Rmd","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/include_gloss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Include gloss in Rmd — include_gloss","text":"","code":"include_gloss(...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/include_gloss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Include gloss in Rmd — include_gloss","text":"... Arguments passed print_gloss().","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_html.html","id":null,"dir":"Reference","previous_headings":"","what":"Lexa HTML document — lexa_html","title":"Lexa HTML document — lexa_html","text":"custom Rmarkdown template typeset HTML documents extra support interlinear glosses. # nolint","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_html.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lexa HTML document — lexa_html","text":"","code":"lexa_html(...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_html.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lexa HTML document — lexa_html","text":"... Arguments passed html_document.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_pdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Lexa PDF document — lexa_pdf","title":"Lexa PDF document — lexa_pdf","text":"custom Rmarkdown template typeset PDF documents extra support interlinear glosses. Note format uses custom Pandoc LaTeX template, incompatibilities bewteen expex unicode-math.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_pdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Lexa PDF document — lexa_pdf","text":"","code":"lexa_pdf(...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/lexa_pdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Lexa PDF document — lexa_pdf","text":"... Arguments passed pdf_document.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/load_lexadb.html","id":null,"dir":"Reference","previous_headings":"","what":"Load Lexa database — load_lexadb","title":"Load Lexa database — load_lexadb","text":"loadds Lexa database specified path. path directory containing database.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/load_lexadb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load Lexa database — load_lexadb","text":"","code":"load_lexadb(path)"},{"path":"https://stefanocoretta.github.io/lexa/reference/load_lexadb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load Lexa database — load_lexadb","text":"path path database string.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/load_lexadb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load Lexa database — load_lexadb","text":"lexadb object.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexadb.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for Lexa databases — print.lexadb","title":"Print method for Lexa databases — print.lexadb","text":"Print method objects class lexadb, prints database info statistics.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexadb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for Lexa databases — print.lexadb","text":"","code":"# S3 method for lexadb print(x, ...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexadb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for Lexa databases — print.lexadb","text":"x object class lexadb. ... Arguments passed print.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexadb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for Lexa databases — print.lexadb","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalx.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for lexemes — print.lexalx","title":"Print method for lexemes — print.lexalx","text":"Print method objects class lexalx, prints lexeme info.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for lexemes — print.lexalx","text":"","code":"# S3 method for lexalx print(x, ...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for lexemes — print.lexalx","text":"x object class lexalx. ... Arguments passed print.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for lexemes — print.lexalx","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalxs.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for list of entries — print.lexalxs","title":"Print method for list of entries — print.lexalxs","text":"Print method output search_lexicon(), returns object class lexalxs.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalxs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for list of entries — print.lexalxs","text":"","code":"# S3 method for lexalxs print(x, ...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalxs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for list of entries — print.lexalxs","text":"x object class lexalxs. ... Arguments passed print.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexalxs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for list of entries — print.lexalxs","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexast.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for sentences — print.lexast","title":"Print method for sentences — print.lexast","text":"Print method objects class lexast, prints text sentences.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for sentences — print.lexast","text":"","code":"# S3 method for lexast print(x, ...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for sentences — print.lexast","text":"x object class lexast. ... Arguments passed print.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for sentences — print.lexast","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexatx.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for texts — print.lexatx","title":"Print method for texts — print.lexatx","text":"Print method objects class lexatx, prints text info.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexatx.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for texts — print.lexatx","text":"","code":"# S3 method for lexatx print(x, ...)"},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexatx.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for texts — print.lexatx","text":"x object class lexatx. ... Arguments passed print.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/print.lexatx.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for texts — print.lexatx","text":"Nothing. Used side effects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_lexicon.html","id":null,"dir":"Reference","previous_headings":"","what":"Search lexicon entries — search_lexicon","title":"Search lexicon entries — search_lexicon","text":"Search entries lexicon, entry form sense definitions.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_lexicon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search lexicon entries — search_lexicon","text":"","code":"search_lexicon(   lexadb,   entry = NULL,   whole = TRUE,   definition = NULL,   pos = NULL )"},{"path":"https://stefanocoretta.github.io/lexa/reference/search_lexicon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search lexicon entries — search_lexicon","text":"lexadb lexadb object (created load_lexadb). entry regular expression search among entries. whole Whether search whole words (applies entry, TRUE default). definition regular expression search among sense definitions. pos regular expression match part speech.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_lexicon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search lexicon entries — search_lexicon","text":"list lexalx objects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Search words in texts — search_texts","title":"Search words in texts — search_texts","text":"Search words texts collection.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Search words in texts — search_texts","text":"","code":"search_texts(lexadb, word = NULL, whole = TRUE, gloss = NULL)"},{"path":"https://stefanocoretta.github.io/lexa/reference/search_texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Search words in texts — search_texts","text":"lexadb lexadb object (created load_lexadb). word regular expression search among sentences. whole Whether search whole words (TRUE default). gloss regular expression search among glosses.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/search_texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Search words in texts — search_texts","text":"list lexalx objects.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_entry.html","id":null,"dir":"Reference","previous_headings":"","what":"Show lexicon entry with given id — show_entry","title":"Show lexicon entry with given id — show_entry","text":"shows entry given id.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_entry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show lexicon entry with given id — show_entry","text":"","code":"show_entry(lexadb, entry_id)"},{"path":"https://stefanocoretta.github.io/lexa/reference/show_entry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show lexicon entry with given id — show_entry","text":"lexadb lexadb object (created load_lexadb). entry_id string entry id (lx_ prefix leading zeros can omitted.)","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_entry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show lexicon entry with given id — show_entry","text":"lexalx object.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_text.html","id":null,"dir":"Reference","previous_headings":"","what":"Show text or sentence with given id — show_text","title":"Show text or sentence with given id — show_text","text":"shows text sentence given id.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_text.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show text or sentence with given id — show_text","text":"","code":"show_text(lexadb, text_id, sent_id = NULL)"},{"path":"https://stefanocoretta.github.io/lexa/reference/show_text.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show text or sentence with given id — show_text","text":"lexadb lexadb object (created load_lexadb). text_id string text id (tx_ prefix leading zeros can omitted.) sent_id string sentence id (st_ prefix leading zeros can omitted.)","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/show_text.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show text or sentence with given id — show_text","text":"lexast object.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/typeset_gloss.html","id":null,"dir":"Reference","previous_headings":"","what":"Typeset interlinear gloss — typeset_gloss","title":"Typeset interlinear gloss — typeset_gloss","text":"function returns selected sentence properly formatted html/latex code.","code":""},{"path":"https://stefanocoretta.github.io/lexa/reference/typeset_gloss.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Typeset interlinear gloss — typeset_gloss","text":"","code":"typeset_gloss(lexadb, text, sentence, format = \"latex\")"},{"path":"https://stefanocoretta.github.io/lexa/reference/typeset_gloss.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Typeset interlinear gloss — typeset_gloss","text":"lexadb lexadb object (created load_lexadb). text Text id. sentence Sentence id print. format Format print (either html latex).","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"added-0-0-1","dir":"Changelog","previous_headings":"","what":"Added","title":"lexa 0.0.1","text":"show_text() show text/sentence based ID.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-1","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.1","text":"Errors importing lexicon csv file. Check presence lexical information printing database, print nothing present. create_lexadb() now creates empty skeleton text.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-0-9006","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.0.9006","text":"Gloss translation PDF output includes quotes.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-0-9005","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.0.9005","text":"Fix error lexa_pdf using bookdown base_format. Underscores glosses now converted \\textunderscore output PDF.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"changed-0-0-0-9005","dir":"Changelog","previous_headings":"","what":"Changed","title":"lexa 0.0.0.9005","text":"typeset_gloss() supports numeric text sentence ID. typeset_gloss() now outputs gloss abbreviations leipzig commands output format PDF. Improved lexa_pdf Rmarkdown template: Using custom LaTeX template circumvent unicode-math incompatibility expex leipzig. Includes list abbreviations glosses leipzig commands (list based Croft Tyopology Universals).","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-0-9004","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.0.9004","text":"Error typeset_gloss() phon present latex format.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-0-9003","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.0.9003","text":"typeset_gloss() returning latex gloss phonetic transcription present.","code":""},{"path":[]},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"breaking-changes-0-0-0-9002","dir":"Changelog","previous_headings":"","what":"Breaking changes","title":"lexa 0.0.0.9002","text":"Renamed import_lexicon() import_lexicon_csv(). create_entry() longer exported. Renamed print_gloss() typeset_gloss().","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"added-0-0-0-9002","dir":"Changelog","previous_headings":"","what":"Added","title":"lexa 0.0.0.9002","text":"search_lexicon() adds pos argument filter part speech. print method lexadb also includes lexicon breakdown numerical summaries. print method lexalx also prints allomorph information , present, examples, etymology notes. lexicon entry schema now following fields: loan_word, crossref, variants, semantics (semantic_domain, synonyms, antonyms), (added senses) literal, scientific usage. Print methods lexatx lexast. Print method lexalxs (returned search_lexicon()). Added albanian database. search_texts() search words glosses texts. show_entry() prints entry given entry_id. Custom RMarkdown templates lexa_pdf lexa_html.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"changed-0-0-0-9002","dir":"Changelog","previous_headings":"","what":"Changed","title":"lexa 0.0.0.9002","text":"create_entry() now exported outputs list entry id string containing entry skeleton. create_entry() now allows user specify values entry fields. add_entry() now passes arguments create_entry() user can specify fields. entry senses now numbered printed. Changed texts schema. search_lexicon() search_texts() now search whole words default. can changed specifying whole = FALSE. lexalx printing method improved.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"fixed-0-0-0-9002","dir":"Changelog","previous_headings":"","what":"Fixed","title":"lexa 0.0.0.9002","text":"Printing interlinear glosses now works even repeated spaces words.","code":""},{"path":"https://stefanocoretta.github.io/lexa/news/index.html","id":"lexa-0009001","dir":"Changelog","previous_headings":"","what":"lexa 0.0.0.9001","title":"lexa 0.0.0.9001","text":"First beta release.","code":""}]
